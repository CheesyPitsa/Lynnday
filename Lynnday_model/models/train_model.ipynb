{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "# import matplotlib.pyplot as plt    # for plotting the images\n",
    "# %matplotlib inline\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nude0</td>\n",
       "      <td>nude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nude1</td>\n",
       "      <td>nude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nude2</td>\n",
       "      <td>nude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nude3</td>\n",
       "      <td>nude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nude4</td>\n",
       "      <td>nude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image class\n",
       "0  nude0  nude\n",
       "1  nude1  nude\n",
       "2  nude2  nude\n",
       "3  nude3  nude\n",
       "4  nude4  nude"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.DataFrame()\n",
    "train_image = []\n",
    "train_class = []\n",
    "for i in range(17000):\n",
    "    train_image.append('nude' + str(i))\n",
    "    train_class.append('nude')\n",
    "for i in range(12000):\n",
    "    train_image.append('safe' + str(i))\n",
    "    train_class.append('safe')\n",
    "for i in range(7000):\n",
    "    train_image.append('sexy' + str(i))\n",
    "    train_class.append('sexy')\n",
    "train_data['image'] = train_image\n",
    "train_data['class'] = train_class\n",
    "train_data.to_csv('train_new.csv',header=True, index=False)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        nude\n",
       "17000    safe\n",
       "29000    sexy\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['class'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_new.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 36000/36000 [06:45<00:00, 88.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36000, 80, 80, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an empty list\n",
    "\n",
    "train_image = []\n",
    "# for loop to read and store frames\n",
    "\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "\n",
    "    # loading the image and keeping the target size as (224,224,3)\n",
    "    img = image.load_img('dataset/'+train['image'][i] + '.jpg', target_size=(80,80,3))\n",
    "\n",
    "    # converting it to array\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    # normalizing the pixel value\n",
    "    img = img/255\n",
    "\n",
    "    # appending the image to the train_image list\n",
    "    train_image.append(img)\n",
    "\n",
    "# converting the list to numpy array\n",
    "X = np.array(train_image)\n",
    "\n",
    "# shape of the array\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.random.uniform(400, 800, size = (45000, 128, 128, 3))\n",
    "print(a.size * a.itemsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the target\n",
    "y = train['class']\n",
    "\n",
    "# creating the training and validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummies of target variable for train and validation set\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nude</th>\n",
       "      <th>safe</th>\n",
       "      <th>sexy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33043</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20349</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19146</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23087</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24171</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2668</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14252</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23754</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nude  safe  sexy\n",
       "29179     0     0     1\n",
       "33043     0     0     1\n",
       "2586      1     0     0\n",
       "20349     0     1     0\n",
       "19146     0     1     0\n",
       "...     ...   ...   ...\n",
       "23087     0     1     0\n",
       "24171     0     1     0\n",
       "2668      1     0     0\n",
       "14252     1     0     0\n",
       "23754     0     1     0\n",
       "\n",
       "[28800 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the base model of pre-trained VGG16 model\n",
    "#base_model = VGG16(weights='imagenet', include_top=False,input_shape=(100,100,3))\n",
    "base_model = tf.keras.applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(80,80,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28800, 2, 2, 512)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for training frames\n",
    "X_train = base_model.predict(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200, 2, 2, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting features for validation frames\n",
    "X_test = base_model.predict(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the training as well as validation frames in single dimension\n",
    "X_train = X_train.reshape(28800, 2*2*512)\n",
    "X_test = X_test.reshape(7200, 2*2*512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.365967\n"
     ]
    }
   ],
   "source": [
    "# normalizing the pixel values\n",
    "max = X_train.max()\n",
    "print(max)\n",
    "X_train = X_train/max\n",
    "X_test = X_test/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28800, 2048)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(2048,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight_80_36000.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy(copy=False)\n",
    "y_test = y_test.to_numpy(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "225/225 [==============================] - 14s 63ms/step - loss: 0.7755 - accuracy: 0.6670 - val_loss: 0.6728 - val_accuracy: 0.7206\n",
      "Epoch 2/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.6539 - accuracy: 0.7308 - val_loss: 0.6078 - val_accuracy: 0.7415\n",
      "Epoch 3/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.6165 - accuracy: 0.7501 - val_loss: 0.5978 - val_accuracy: 0.7462\n",
      "Epoch 4/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.5865 - accuracy: 0.7611 - val_loss: 0.5887 - val_accuracy: 0.7518\n",
      "Epoch 5/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.5696 - accuracy: 0.7683 - val_loss: 0.5770 - val_accuracy: 0.7592\n",
      "Epoch 6/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.5545 - accuracy: 0.7763 - val_loss: 0.5768 - val_accuracy: 0.7644\n",
      "Epoch 7/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.5360 - accuracy: 0.7823 - val_loss: 0.5798 - val_accuracy: 0.7618\n",
      "Epoch 8/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.5225 - accuracy: 0.7894 - val_loss: 0.5824 - val_accuracy: 0.7682\n",
      "Epoch 9/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.5048 - accuracy: 0.7972 - val_loss: 0.5882 - val_accuracy: 0.7588\n",
      "Epoch 10/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.4890 - accuracy: 0.8030 - val_loss: 0.5683 - val_accuracy: 0.7668\n",
      "Epoch 11/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.4758 - accuracy: 0.8088 - val_loss: 0.5784 - val_accuracy: 0.7643\n",
      "Epoch 12/200\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.4599 - accuracy: 0.8143 - val_loss: 0.5834 - val_accuracy: 0.7667\n",
      "Epoch 13/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.4431 - accuracy: 0.8243 - val_loss: 0.5904 - val_accuracy: 0.7681\n",
      "Epoch 14/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.4263 - accuracy: 0.8283 - val_loss: 0.5857 - val_accuracy: 0.7710\n",
      "Epoch 15/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.4108 - accuracy: 0.8355 - val_loss: 0.6139 - val_accuracy: 0.7686\n",
      "Epoch 16/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.4001 - accuracy: 0.8401 - val_loss: 0.6090 - val_accuracy: 0.7715\n",
      "Epoch 17/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.3835 - accuracy: 0.8467 - val_loss: 0.6257 - val_accuracy: 0.7675\n",
      "Epoch 18/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.3693 - accuracy: 0.8551 - val_loss: 0.6312 - val_accuracy: 0.7643\n",
      "Epoch 19/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.3574 - accuracy: 0.8594 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
      "Epoch 20/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.3421 - accuracy: 0.8658 - val_loss: 0.6431 - val_accuracy: 0.7672\n",
      "Epoch 21/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.3287 - accuracy: 0.8711 - val_loss: 0.6663 - val_accuracy: 0.7653\n",
      "Epoch 22/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.3265 - accuracy: 0.8711 - val_loss: 0.6737 - val_accuracy: 0.7639\n",
      "Epoch 23/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.3097 - accuracy: 0.8774 - val_loss: 0.7050 - val_accuracy: 0.7651\n",
      "Epoch 24/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.2924 - accuracy: 0.8856 - val_loss: 0.7071 - val_accuracy: 0.7621\n",
      "Epoch 25/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.2921 - accuracy: 0.8852 - val_loss: 0.7028 - val_accuracy: 0.7557\n",
      "Epoch 26/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.2754 - accuracy: 0.8942 - val_loss: 0.7116 - val_accuracy: 0.7663\n",
      "Epoch 27/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.2724 - accuracy: 0.8931 - val_loss: 0.7055 - val_accuracy: 0.7694\n",
      "Epoch 28/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.2560 - accuracy: 0.8988 - val_loss: 0.7501 - val_accuracy: 0.7663\n",
      "Epoch 29/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.2566 - accuracy: 0.9008 - val_loss: 0.7639 - val_accuracy: 0.7621\n",
      "Epoch 30/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.2456 - accuracy: 0.9056 - val_loss: 0.7866 - val_accuracy: 0.7668\n",
      "Epoch 31/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.2304 - accuracy: 0.9106 - val_loss: 0.8185 - val_accuracy: 0.7694\n",
      "Epoch 32/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.2266 - accuracy: 0.9122 - val_loss: 0.8287 - val_accuracy: 0.7629\n",
      "Epoch 33/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.2236 - accuracy: 0.9145 - val_loss: 0.7974 - val_accuracy: 0.7657\n",
      "Epoch 34/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.2185 - accuracy: 0.9149 - val_loss: 0.8154 - val_accuracy: 0.7638\n",
      "Epoch 35/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.2103 - accuracy: 0.9206 - val_loss: 0.8888 - val_accuracy: 0.7593\n",
      "Epoch 36/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.2067 - accuracy: 0.9231 - val_loss: 0.8553 - val_accuracy: 0.7631\n",
      "Epoch 37/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.2016 - accuracy: 0.9242 - val_loss: 0.8822 - val_accuracy: 0.7585\n",
      "Epoch 38/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.1987 - accuracy: 0.9235 - val_loss: 0.8561 - val_accuracy: 0.7650\n",
      "Epoch 39/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.1894 - accuracy: 0.9274 - val_loss: 0.8910 - val_accuracy: 0.7571\n",
      "Epoch 40/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.1925 - accuracy: 0.9252 - val_loss: 0.8735 - val_accuracy: 0.7685\n",
      "Epoch 41/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.1786 - accuracy: 0.9301 - val_loss: 1.0249 - val_accuracy: 0.7667\n",
      "Epoch 42/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.1692 - accuracy: 0.9357 - val_loss: 0.9786 - val_accuracy: 0.7560\n",
      "Epoch 43/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.1752 - accuracy: 0.9326 - val_loss: 1.0418 - val_accuracy: 0.7617\n",
      "Epoch 44/200\n",
      "225/225 [==============================] - 14s 63ms/step - loss: 0.1670 - accuracy: 0.9363 - val_loss: 1.0056 - val_accuracy: 0.7628\n",
      "Epoch 45/200\n",
      "225/225 [==============================] - 14s 61ms/step - loss: 0.1575 - accuracy: 0.9389 - val_loss: 0.9914 - val_accuracy: 0.7629\n",
      "Epoch 46/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.1564 - accuracy: 0.9404 - val_loss: 1.0385 - val_accuracy: 0.7631\n",
      "Epoch 47/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.1526 - accuracy: 0.9422 - val_loss: 1.0131 - val_accuracy: 0.7569\n",
      "Epoch 48/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.1575 - accuracy: 0.9406 - val_loss: 1.0218 - val_accuracy: 0.7604\n",
      "Epoch 49/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.1470 - accuracy: 0.9453 - val_loss: 1.0313 - val_accuracy: 0.7636\n",
      "Epoch 50/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.1506 - accuracy: 0.9418 - val_loss: 1.0073 - val_accuracy: 0.7628\n",
      "Epoch 51/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.1494 - accuracy: 0.9432 - val_loss: 1.0203 - val_accuracy: 0.7615\n",
      "Epoch 52/200\n",
      "225/225 [==============================] - 14s 61ms/step - loss: 0.1449 - accuracy: 0.9462 - val_loss: 1.0054 - val_accuracy: 0.7642\n",
      "Epoch 53/200\n",
      "225/225 [==============================] - 16s 70ms/step - loss: 0.1383 - accuracy: 0.9483 - val_loss: 1.0800 - val_accuracy: 0.7585\n",
      "Epoch 54/200\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 0.1403 - accuracy: 0.9471 - val_loss: 1.1145 - val_accuracy: 0.7578\n",
      "Epoch 55/200\n",
      "225/225 [==============================] - 14s 62ms/step - loss: 0.1357 - accuracy: 0.9499 - val_loss: 1.1591 - val_accuracy: 0.7624\n",
      "Epoch 56/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.1358 - accuracy: 0.9491 - val_loss: 1.1290 - val_accuracy: 0.7622\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 14s 60ms/step - loss: 0.1315 - accuracy: 0.9521 - val_loss: 1.1059 - val_accuracy: 0.7604\n",
      "Epoch 58/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.1241 - accuracy: 0.9542 - val_loss: 1.1364 - val_accuracy: 0.7613\n",
      "Epoch 59/200\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.1299 - accuracy: 0.9530 - val_loss: 1.0975 - val_accuracy: 0.7619\n",
      "Epoch 60/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.1265 - accuracy: 0.9531 - val_loss: 1.1292 - val_accuracy: 0.7599\n",
      "Epoch 61/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.1214 - accuracy: 0.9538 - val_loss: 1.1298 - val_accuracy: 0.7593\n",
      "Epoch 62/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.1215 - accuracy: 0.9552 - val_loss: 1.1047 - val_accuracy: 0.7621\n",
      "Epoch 63/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1206 - accuracy: 0.9541 - val_loss: 1.2418 - val_accuracy: 0.7633\n",
      "Epoch 64/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.1269 - accuracy: 0.9534 - val_loss: 1.0878 - val_accuracy: 0.7631\n",
      "Epoch 65/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.1189 - accuracy: 0.9553 - val_loss: 1.1567 - val_accuracy: 0.7617\n",
      "Epoch 66/200\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.1151 - accuracy: 0.9569 - val_loss: 1.2542 - val_accuracy: 0.7643\n",
      "Epoch 67/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1202 - accuracy: 0.9566 - val_loss: 1.1157 - val_accuracy: 0.7658\n",
      "Epoch 68/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.1134 - accuracy: 0.9577 - val_loss: 1.2866 - val_accuracy: 0.7636\n",
      "Epoch 69/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.1131 - accuracy: 0.9581 - val_loss: 1.2237 - val_accuracy: 0.7574\n",
      "Epoch 70/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.1130 - accuracy: 0.9593 - val_loss: 1.0932 - val_accuracy: 0.7629\n",
      "Epoch 71/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1135 - accuracy: 0.9589 - val_loss: 1.1676 - val_accuracy: 0.7596\n",
      "Epoch 72/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1013 - accuracy: 0.9622 - val_loss: 1.2325 - val_accuracy: 0.7614\n",
      "Epoch 73/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.1054 - accuracy: 0.9617 - val_loss: 1.2389 - val_accuracy: 0.7633\n",
      "Epoch 74/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.1100 - accuracy: 0.9601 - val_loss: 1.2634 - val_accuracy: 0.7613\n",
      "Epoch 75/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.1014 - accuracy: 0.9626 - val_loss: 1.3056 - val_accuracy: 0.7651\n",
      "Epoch 76/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.1046 - accuracy: 0.9628 - val_loss: 1.1776 - val_accuracy: 0.7608\n",
      "Epoch 77/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.1093 - accuracy: 0.9589 - val_loss: 1.0834 - val_accuracy: 0.7667\n",
      "Epoch 78/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.1007 - accuracy: 0.9637 - val_loss: 1.1983 - val_accuracy: 0.7633\n",
      "Epoch 79/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0927 - accuracy: 0.9658 - val_loss: 1.2998 - val_accuracy: 0.7636\n",
      "Epoch 80/200\n",
      "225/225 [==============================] - 14s 62ms/step - loss: 0.1024 - accuracy: 0.9624 - val_loss: 1.2059 - val_accuracy: 0.7596\n",
      "Epoch 81/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.1028 - accuracy: 0.9638 - val_loss: 1.1695 - val_accuracy: 0.7574\n",
      "Epoch 82/200\n",
      "225/225 [==============================] - 14s 63ms/step - loss: 0.0981 - accuracy: 0.9642 - val_loss: 1.1443 - val_accuracy: 0.7574\n",
      "Epoch 83/200\n",
      "225/225 [==============================] - 14s 64ms/step - loss: 0.0928 - accuracy: 0.9660 - val_loss: 1.2530 - val_accuracy: 0.7608\n",
      "Epoch 84/200\n",
      "225/225 [==============================] - 15s 65ms/step - loss: 0.0953 - accuracy: 0.9648 - val_loss: 1.2438 - val_accuracy: 0.7599\n",
      "Epoch 85/200\n",
      "225/225 [==============================] - 14s 61ms/step - loss: 0.0993 - accuracy: 0.9638 - val_loss: 1.2198 - val_accuracy: 0.7688\n",
      "Epoch 86/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.0916 - accuracy: 0.9674 - val_loss: 1.3337 - val_accuracy: 0.7633\n",
      "Epoch 87/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0927 - accuracy: 0.9660 - val_loss: 1.2827 - val_accuracy: 0.7618\n",
      "Epoch 88/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0940 - accuracy: 0.9658 - val_loss: 1.3742 - val_accuracy: 0.7632\n",
      "Epoch 89/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.0953 - accuracy: 0.9664 - val_loss: 1.2770 - val_accuracy: 0.7643\n",
      "Epoch 90/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.0923 - accuracy: 0.9666 - val_loss: 1.1882 - val_accuracy: 0.7579\n",
      "Epoch 91/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0900 - accuracy: 0.9674 - val_loss: 1.3094 - val_accuracy: 0.7599\n",
      "Epoch 92/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0903 - accuracy: 0.9685 - val_loss: 1.2224 - val_accuracy: 0.7604\n",
      "Epoch 93/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0865 - accuracy: 0.9707 - val_loss: 1.3173 - val_accuracy: 0.7585\n",
      "Epoch 94/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.0813 - accuracy: 0.9709 - val_loss: 1.2084 - val_accuracy: 0.7596\n",
      "Epoch 95/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0857 - accuracy: 0.9692 - val_loss: 1.3525 - val_accuracy: 0.7650\n",
      "Epoch 96/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.0892 - accuracy: 0.9685 - val_loss: 1.3738 - val_accuracy: 0.7614\n",
      "Epoch 97/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.0866 - accuracy: 0.9675 - val_loss: 1.3314 - val_accuracy: 0.7650\n",
      "Epoch 98/200\n",
      "225/225 [==============================] - 13s 60ms/step - loss: 0.0796 - accuracy: 0.9713 - val_loss: 1.3995 - val_accuracy: 0.7601\n",
      "Epoch 99/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0825 - accuracy: 0.9698 - val_loss: 1.2846 - val_accuracy: 0.7563\n",
      "Epoch 100/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0782 - accuracy: 0.9720 - val_loss: 1.3313 - val_accuracy: 0.7661\n",
      "Epoch 101/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.0844 - accuracy: 0.9699 - val_loss: 1.2678 - val_accuracy: 0.7628\n",
      "Epoch 102/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0808 - accuracy: 0.9694 - val_loss: 1.5137 - val_accuracy: 0.7601\n",
      "Epoch 103/200\n",
      "225/225 [==============================] - 12s 56ms/step - loss: 0.0890 - accuracy: 0.9684 - val_loss: 1.3741 - val_accuracy: 0.7603\n",
      "Epoch 104/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0846 - accuracy: 0.9702 - val_loss: 1.3515 - val_accuracy: 0.7606\n",
      "Epoch 105/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.0793 - accuracy: 0.9715 - val_loss: 1.3251 - val_accuracy: 0.7600\n",
      "Epoch 106/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.0790 - accuracy: 0.9718 - val_loss: 1.2780 - val_accuracy: 0.7657\n",
      "Epoch 107/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0832 - accuracy: 0.9699 - val_loss: 1.3498 - val_accuracy: 0.7658\n",
      "Epoch 108/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.0818 - accuracy: 0.9711 - val_loss: 1.1700 - val_accuracy: 0.7626\n",
      "Epoch 109/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.0719 - accuracy: 0.9745 - val_loss: 1.4310 - val_accuracy: 0.7608\n",
      "Epoch 110/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.0829 - accuracy: 0.9710 - val_loss: 1.2274 - val_accuracy: 0.7593\n",
      "Epoch 111/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0822 - accuracy: 0.9712 - val_loss: 1.2907 - val_accuracy: 0.7594\n",
      "Epoch 112/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0837 - accuracy: 0.9707 - val_loss: 1.1858 - val_accuracy: 0.7632\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0767 - accuracy: 0.9719 - val_loss: 1.6000 - val_accuracy: 0.7667\n",
      "Epoch 114/200\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.0729 - accuracy: 0.9744 - val_loss: 1.4237 - val_accuracy: 0.7615\n",
      "Epoch 115/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0765 - accuracy: 0.9736 - val_loss: 1.4208 - val_accuracy: 0.7638\n",
      "Epoch 116/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.0749 - accuracy: 0.9739 - val_loss: 1.3408 - val_accuracy: 0.7640\n",
      "Epoch 117/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0821 - accuracy: 0.9706 - val_loss: 1.3937 - val_accuracy: 0.7594\n",
      "Epoch 118/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0796 - accuracy: 0.9723 - val_loss: 1.3168 - val_accuracy: 0.7608\n",
      "Epoch 119/200\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.0703 - accuracy: 0.9750 - val_loss: 1.4296 - val_accuracy: 0.7628\n",
      "Epoch 120/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.0750 - accuracy: 0.9728 - val_loss: 1.3298 - val_accuracy: 0.7636\n",
      "Epoch 121/200\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.0780 - accuracy: 0.9727 - val_loss: 1.2662 - val_accuracy: 0.7592\n",
      "Epoch 122/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0740 - accuracy: 0.9731 - val_loss: 1.4913 - val_accuracy: 0.7621\n",
      "Epoch 123/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.0691 - accuracy: 0.9769 - val_loss: 1.4088 - val_accuracy: 0.7611\n",
      "Epoch 124/200\n",
      "225/225 [==============================] - 12s 51ms/step - loss: 0.0745 - accuracy: 0.9728 - val_loss: 1.3949 - val_accuracy: 0.7622\n",
      "Epoch 125/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0720 - accuracy: 0.9744 - val_loss: 1.4564 - val_accuracy: 0.7619\n",
      "Epoch 126/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0724 - accuracy: 0.9745 - val_loss: 1.3057 - val_accuracy: 0.7625\n",
      "Epoch 127/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0749 - accuracy: 0.9751 - val_loss: 1.2018 - val_accuracy: 0.7589\n",
      "Epoch 128/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0649 - accuracy: 0.9761 - val_loss: 1.4875 - val_accuracy: 0.7635\n",
      "Epoch 129/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0743 - accuracy: 0.9731 - val_loss: 1.4966 - val_accuracy: 0.7604\n",
      "Epoch 130/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0699 - accuracy: 0.9744 - val_loss: 1.6075 - val_accuracy: 0.7608\n",
      "Epoch 131/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0685 - accuracy: 0.9751 - val_loss: 1.3997 - val_accuracy: 0.7625\n",
      "Epoch 132/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0737 - accuracy: 0.9725 - val_loss: 1.4587 - val_accuracy: 0.7663\n",
      "Epoch 133/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0641 - accuracy: 0.9775 - val_loss: 1.4915 - val_accuracy: 0.7594\n",
      "Epoch 134/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0664 - accuracy: 0.9777 - val_loss: 1.5015 - val_accuracy: 0.7625\n",
      "Epoch 135/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0717 - accuracy: 0.9743 - val_loss: 1.2618 - val_accuracy: 0.7582\n",
      "Epoch 136/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0707 - accuracy: 0.9758 - val_loss: 1.4114 - val_accuracy: 0.7646\n",
      "Epoch 137/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0666 - accuracy: 0.9762 - val_loss: 1.4738 - val_accuracy: 0.7621\n",
      "Epoch 138/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.0633 - accuracy: 0.9772 - val_loss: 1.5486 - val_accuracy: 0.7635\n",
      "Epoch 139/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0664 - accuracy: 0.9766 - val_loss: 1.4544 - val_accuracy: 0.7644\n",
      "Epoch 140/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0601 - accuracy: 0.9788 - val_loss: 1.4861 - val_accuracy: 0.7646\n",
      "Epoch 141/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 1.5063 - val_accuracy: 0.7599\n",
      "Epoch 142/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0658 - accuracy: 0.9761 - val_loss: 1.4667 - val_accuracy: 0.7632\n",
      "Epoch 143/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0645 - accuracy: 0.9774 - val_loss: 1.3707 - val_accuracy: 0.7607\n",
      "Epoch 144/200\n",
      "225/225 [==============================] - 13s 59ms/step - loss: 0.0638 - accuracy: 0.9777 - val_loss: 1.6796 - val_accuracy: 0.7594\n",
      "Epoch 145/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0673 - accuracy: 0.9762 - val_loss: 1.3215 - val_accuracy: 0.7638\n",
      "Epoch 146/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0629 - accuracy: 0.9773 - val_loss: 1.5483 - val_accuracy: 0.7597\n",
      "Epoch 147/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0593 - accuracy: 0.9786 - val_loss: 1.5027 - val_accuracy: 0.7590\n",
      "Epoch 148/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0628 - accuracy: 0.9773 - val_loss: 1.4232 - val_accuracy: 0.7522\n",
      "Epoch 149/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0643 - accuracy: 0.9783 - val_loss: 1.5817 - val_accuracy: 0.7607\n",
      "Epoch 150/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0626 - accuracy: 0.9770 - val_loss: 1.5164 - val_accuracy: 0.7596\n",
      "Epoch 151/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0606 - accuracy: 0.9786 - val_loss: 1.4830 - val_accuracy: 0.7597\n",
      "Epoch 152/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.0642 - accuracy: 0.9776 - val_loss: 1.4385 - val_accuracy: 0.7568\n",
      "Epoch 153/200\n",
      "225/225 [==============================] - 13s 57ms/step - loss: 0.0610 - accuracy: 0.9798 - val_loss: 1.4316 - val_accuracy: 0.7653\n",
      "Epoch 154/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0618 - accuracy: 0.9785 - val_loss: 1.5007 - val_accuracy: 0.7635\n",
      "Epoch 155/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0589 - accuracy: 0.9797 - val_loss: 1.4113 - val_accuracy: 0.7597\n",
      "Epoch 156/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0653 - accuracy: 0.9778 - val_loss: 1.3606 - val_accuracy: 0.7635\n",
      "Epoch 157/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0620 - accuracy: 0.9782 - val_loss: 1.4223 - val_accuracy: 0.7615\n",
      "Epoch 158/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0597 - accuracy: 0.9796 - val_loss: 1.5480 - val_accuracy: 0.7626\n",
      "Epoch 159/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0557 - accuracy: 0.9798 - val_loss: 1.6989 - val_accuracy: 0.7618\n",
      "Epoch 160/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0669 - accuracy: 0.9772 - val_loss: 1.4817 - val_accuracy: 0.7608\n",
      "Epoch 161/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0582 - accuracy: 0.9795 - val_loss: 1.5925 - val_accuracy: 0.7626\n",
      "Epoch 162/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0591 - accuracy: 0.9803 - val_loss: 1.3908 - val_accuracy: 0.7626\n",
      "Epoch 163/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0607 - accuracy: 0.9787 - val_loss: 1.5038 - val_accuracy: 0.7592\n",
      "Epoch 164/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0585 - accuracy: 0.9803 - val_loss: 1.4685 - val_accuracy: 0.7635\n",
      "Epoch 165/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0612 - accuracy: 0.9785 - val_loss: 1.4639 - val_accuracy: 0.7601\n",
      "Epoch 166/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0593 - accuracy: 0.9798 - val_loss: 1.5575 - val_accuracy: 0.7608\n",
      "Epoch 167/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0596 - accuracy: 0.9794 - val_loss: 1.4364 - val_accuracy: 0.7654\n",
      "Epoch 168/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0518 - accuracy: 0.9820 - val_loss: 1.4922 - val_accuracy: 0.7622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "225/225 [==============================] - 11s 48ms/step - loss: 0.0594 - accuracy: 0.9797 - val_loss: 1.5195 - val_accuracy: 0.7639\n",
      "Epoch 170/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0582 - accuracy: 0.9799 - val_loss: 1.7792 - val_accuracy: 0.7667\n",
      "Epoch 171/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.0608 - accuracy: 0.9783 - val_loss: 1.5359 - val_accuracy: 0.7633\n",
      "Epoch 172/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.0564 - accuracy: 0.9810 - val_loss: 1.5330 - val_accuracy: 0.7683\n",
      "Epoch 173/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.0549 - accuracy: 0.9816 - val_loss: 1.5357 - val_accuracy: 0.7636\n",
      "Epoch 174/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0588 - accuracy: 0.9791 - val_loss: 1.4333 - val_accuracy: 0.7658\n",
      "Epoch 175/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 1.5721 - val_accuracy: 0.7621\n",
      "Epoch 176/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0525 - accuracy: 0.9808 - val_loss: 1.8070 - val_accuracy: 0.7585\n",
      "Epoch 177/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0581 - accuracy: 0.9807 - val_loss: 1.5342 - val_accuracy: 0.7618\n",
      "Epoch 178/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.0599 - accuracy: 0.9795 - val_loss: 1.5490 - val_accuracy: 0.7592\n",
      "Epoch 179/200\n",
      "225/225 [==============================] - 11s 50ms/step - loss: 0.0548 - accuracy: 0.9812 - val_loss: 1.6066 - val_accuracy: 0.7604\n",
      "Epoch 180/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0513 - accuracy: 0.9822 - val_loss: 1.5473 - val_accuracy: 0.7644\n",
      "Epoch 181/200\n",
      "225/225 [==============================] - 12s 52ms/step - loss: 0.0551 - accuracy: 0.9801 - val_loss: 1.5571 - val_accuracy: 0.7611\n",
      "Epoch 182/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.0499 - accuracy: 0.9830 - val_loss: 1.6383 - val_accuracy: 0.7604\n",
      "Epoch 183/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.0590 - accuracy: 0.9797 - val_loss: 1.6676 - val_accuracy: 0.7650\n",
      "Epoch 184/200\n",
      "225/225 [==============================] - 11s 48ms/step - loss: 0.0550 - accuracy: 0.9812 - val_loss: 1.5268 - val_accuracy: 0.7547\n",
      "Epoch 185/200\n",
      "225/225 [==============================] - 11s 47ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 1.5188 - val_accuracy: 0.7635\n",
      "Epoch 186/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.0550 - accuracy: 0.9815 - val_loss: 1.7087 - val_accuracy: 0.7633\n",
      "Epoch 187/200\n",
      "225/225 [==============================] - 11s 49ms/step - loss: 0.0573 - accuracy: 0.9803 - val_loss: 1.3852 - val_accuracy: 0.7610\n",
      "Epoch 188/200\n",
      "225/225 [==============================] - 11s 51ms/step - loss: 0.0491 - accuracy: 0.9827 - val_loss: 1.6219 - val_accuracy: 0.7607\n",
      "Epoch 189/200\n",
      "225/225 [==============================] - 13s 56ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 1.4966 - val_accuracy: 0.7615\n",
      "Epoch 190/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0578 - accuracy: 0.9808 - val_loss: 1.4378 - val_accuracy: 0.7619\n",
      "Epoch 191/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0471 - accuracy: 0.9835 - val_loss: 1.6275 - val_accuracy: 0.7622\n",
      "Epoch 192/200\n",
      "225/225 [==============================] - 12s 53ms/step - loss: 0.0533 - accuracy: 0.9818 - val_loss: 1.6754 - val_accuracy: 0.7619\n",
      "Epoch 193/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0499 - accuracy: 0.9827 - val_loss: 1.6167 - val_accuracy: 0.7631\n",
      "Epoch 194/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0503 - accuracy: 0.9824 - val_loss: 1.5875 - val_accuracy: 0.7642\n",
      "Epoch 195/200\n",
      "225/225 [==============================] - 12s 55ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 1.7854 - val_accuracy: 0.7565\n",
      "Epoch 196/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 1.4835 - val_accuracy: 0.7604\n",
      "Epoch 197/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0565 - accuracy: 0.9802 - val_loss: 1.6184 - val_accuracy: 0.7628\n",
      "Epoch 198/200\n",
      "225/225 [==============================] - 12s 54ms/step - loss: 0.0515 - accuracy: 0.9824 - val_loss: 1.5469 - val_accuracy: 0.7576\n",
      "Epoch 199/200\n",
      "225/225 [==============================] - 13s 58ms/step - loss: 0.0528 - accuracy: 0.9819 - val_loss: 1.5931 - val_accuracy: 0.7590\n",
      "Epoch 200/200\n",
      "225/225 [==============================] - 12s 56ms/step - loss: 0.0487 - accuracy: 0.9830 - val_loss: 1.7324 - val_accuracy: 0.7628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20cdb9e7970>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,787,587\n",
      "Trainable params: 2,787,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
